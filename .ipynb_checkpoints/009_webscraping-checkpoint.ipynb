{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea4af8cf-53d9-4be9-a7c1-31eaf28d3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self, url: str, folder: str):\n",
    "        self.url = url\n",
    "        self.folder = folder\n",
    "        self.soup = self.scrape()\n",
    "        self.chapter = self.soup.find('title').text.replace(\" \", \"_\")\n",
    "\n",
    "    def scrape(self):\n",
    "        req = Request(self.url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        url_content = urlopen(req).read()\n",
    "        return BeautifulSoup(url_content, \"lxml\")\n",
    "    \n",
    "    def clean_div(self, *attribs):\n",
    "        for attrib in attribs:\n",
    "            div_tags = self.soup.find_all('div', class_=attrib)\n",
    "            for div in div_tags:\n",
    "                div.extract()\n",
    "    \n",
    "    def clean_subdiv(self, div, att, sub_att):\n",
    "        parent_div = self.soup.find(div, class_=att) \n",
    "\n",
    "        if parent_div:\n",
    "            subdivision_div = parent_div.find(div, class_=sub_att)  \n",
    "            if subdivision_div:\n",
    "                subdivision_div.extract()\n",
    "\n",
    "    def clean_text(self):\n",
    "        \n",
    "        self.raw = (self.soup.text\n",
    "               .split('©')[0]\n",
    "               .split('>')[-1]\n",
    "               .strip()\n",
    "               )\n",
    "       \n",
    "\n",
    "    def save_json(self):\n",
    "        \n",
    "        # Specify the filename\n",
    "        json_name = f'{self.chapter}.json'   \n",
    "\n",
    "        # Create the folder if it doesn't exist\n",
    "        Path(self.folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Construct the file path\n",
    "        json_path = Path(self.folder) / json_name\n",
    "\n",
    "        data = {}\n",
    "        matches = re.findall(r'(\\d+)\\s+([\\s\\S]*?)(?=\\d|$)', self.raw)\n",
    "        for match in matches:\n",
    "            key = match[0]\n",
    "            value = match[1].strip()\n",
    "            data[key] = value\n",
    "\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "        print(\"JSON data saved to:\", json_path)\n",
    "\n",
    "        \n",
    "        \n",
    "# Example usage:\n",
    "url = \"https://scriptureearth.org/data/bom/sab/bom/bom-22-SNG-001.html\"\n",
    "scraper = WebScraper(url, 'berom')\n",
    "txt = scraper.soup\n",
    "chpt_name = scraper.chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "449ac864-a915-45e1-b934-03bf632cbbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: berom/Lwɛlɛ_Sɔlɔmɔn_1.json\n",
      "1 Lwɛlɛ̂ Sɔlɔmɔn de gwa dal lɛlɛ mwa na neta,\n",
      "\n",
      "\n",
      "2 Ka hwà yang man ranang na me!\n",
      "Yaga tɛ̂ yey mo ha dal na neta e ra nshî anap.\n",
      "3 Něy mɔmɔ mo ne ro nesang hyɔɔlɔl,\n",
      "wôk reza mo zɔng ha sé rat sede wok nesang něy.\n",
      "Yaga ano de beha mwa be tɛ̀ yey na hwo.\n",
      "4 Jut me, na wot a nára hot!\n",
      "À gbɔng gwɔ̀m hom, yel na me e duk pɔlɔ mō,\n",
      "tik na wot vɔk yey pyɛng na wot ra nzem tɛ̂ yey mo,\n",
      "wot ê somo tɛ̂ yey mo hɛ dal nshî anap.\n",
      "A sé tyɛng be tɛ̀ yey na hwo.\n",
      "5 À behwong Yɛrusalɛm, ma sé nèros bes, ko kasâng-hwong,\n",
      "nèros sede bûk hey e Kedar,\n",
      "ko zɛrɛ sede berugû tɔrɔ̂ lɔ Gbɔng Gwɔ̀m Sɔlɔmɔn.\n",
      "6 Yin lòlo bayis e ra me yaga ma sé nèros wɛt,\n",
      "yaga e gwi gwɛ gwa tɛ̀ me ano.\n",
      "Begwa hom ba vɔk shom na me,\n",
      "ba tɛ̀ me mwât bɛrɛng bě anap,\n",
      "ko ma bɛrɛng to hom wɛt, sede bwi de ba hala gwɛ.\n",
      "7 À wò yey hom, ha a me,\n",
      "kwɔn de hwó gyenges ɛ vyēl mo,\n",
      "na kwɔn de hwó tik yɛ ye dyɛng ɛ e necam nagwi.\n",
      "Ano mê kyě rɔ̀nɔs jáma mo e kara mó vè behak wɛt.\n",
      "\n",
      "8 Ka hwà tɔk wɛt, à hwo de hwà dal sé zɛrɛ e ji behwong,\n",
      "raa nekyɔ̌n kwarâ vyēl mo,\n",
      "hwô sɛ̀ a nèy vyēl mo kwɔn de hwô gyeng ɛ yɛ\n",
      "bagat na bǔk bemât gyeng vyēl.\n",
      "9 À sa hom, ma tyɛngrɛ hwo\n",
      "sede gwining e ji bedwa de ba tɔrɔ na nzem yaga hwɔlɔ̂ kyɛkyɛ̂ Farawo.\n",
      "10 Rànang mo ba sé rat na yɔ̄bɔ betong,\n",
      "fwɔ mo gwa sé rwat na lɛlɛ̂ fwɔ.\n",
      "11 Tik na be yóng a hwo nerwěy ne dyam shinang,\n",
      "na be dak ɛ dyam pyɛng.\n",
      "\n",
      "12 Jeng de gbɔng gwɔ̀m a sé e dyɛngɛ e ra gwat mɛ,\n",
      "e sɔ nesang hyɔɔlɔl něy nât nerat e rebek hom.\n",
      "13 Wò yey hom e dyɛngɛ e tê bavasal hom,\n",
      "sede radîng něy mir.\n",
      "14 Wò yey hom a sé sede gushuk bejamûk hey,\n",
      "de ba ga tabas e bwî anap Ɛn-Gɛdi.\n",
      "\n",
      "15 À sa hom, hwà sé zɛrɛ,\n",
      "hwà sé zɛrɛ e ryat wɛt,\n",
      "bayis mo ba vɔk nehywɛ sede bebɔp.\n",
      "\n",
      "16 À wò yey hom, hwà sé zɛrɛ, kasâng-wen,\n",
      "tik wot a jut sɔng lwâ hey sede gwat mot,\n",
      "17 cɔ́gɔt sida sede sesêk lɔ mot,\n",
      "cɔ́gɔt fir sede yê kak o arɔng,\n"
     ]
    }
   ],
   "source": [
    "attribs = ('ms', 'mt', 'sp')\n",
    "scraper.clean_div(attribs)\n",
    "scraper.clean_subdiv('div', 'm', 'c-drop')\n",
    "scraper.clean_text()\n",
    "scraper.save_json()\n",
    "print(scraper.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a5bbd-68c4-4ff9-b77f-eb43e80c4b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
